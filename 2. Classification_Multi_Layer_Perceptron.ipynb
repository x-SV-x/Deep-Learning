{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "649a9821-9ff9-40bf-a467-6cf83b07acbb",
   "metadata": {},
   "source": [
    "**Author :** Vaibhav Thakur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d94808e8-4b04-4d9b-895d-50bcadb29c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AFP</th>\n",
       "      <th>AG</th>\n",
       "      <th>Age</th>\n",
       "      <th>ALB</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>BASO#</th>\n",
       "      <th>BASO%</th>\n",
       "      <th>BUN</th>\n",
       "      <th>...</th>\n",
       "      <th>PCT</th>\n",
       "      <th>PDW</th>\n",
       "      <th>PHOS</th>\n",
       "      <th>PLT</th>\n",
       "      <th>RBC</th>\n",
       "      <th>RDW</th>\n",
       "      <th>TBIL</th>\n",
       "      <th>TP</th>\n",
       "      <th>UA</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.58</td>\n",
       "      <td>19.36</td>\n",
       "      <td>47</td>\n",
       "      <td>45.4</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>13.4</td>\n",
       "      <td>1.46</td>\n",
       "      <td>74</td>\n",
       "      <td>2.64</td>\n",
       "      <td>13.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>73.9</td>\n",
       "      <td>396.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.24</td>\n",
       "      <td>23.98</td>\n",
       "      <td>61</td>\n",
       "      <td>39.9</td>\n",
       "      <td>95</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1.09</td>\n",
       "      <td>304</td>\n",
       "      <td>4.89</td>\n",
       "      <td>12.7</td>\n",
       "      <td>6.8</td>\n",
       "      <td>72.0</td>\n",
       "      <td>119.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.50</td>\n",
       "      <td>18.40</td>\n",
       "      <td>39</td>\n",
       "      <td>45.4</td>\n",
       "      <td>77</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.60</td>\n",
       "      <td>3.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13</td>\n",
       "      <td>15.2</td>\n",
       "      <td>0.97</td>\n",
       "      <td>112</td>\n",
       "      <td>4.62</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>77.9</td>\n",
       "      <td>209.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.75</td>\n",
       "      <td>16.60</td>\n",
       "      <td>45</td>\n",
       "      <td>39.2</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.74</td>\n",
       "      <td>5.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>17.4</td>\n",
       "      <td>1.25</td>\n",
       "      <td>339</td>\n",
       "      <td>4.01</td>\n",
       "      <td>14.6</td>\n",
       "      <td>10.9</td>\n",
       "      <td>66.1</td>\n",
       "      <td>215.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.36</td>\n",
       "      <td>19.97</td>\n",
       "      <td>45</td>\n",
       "      <td>35.0</td>\n",
       "      <td>47</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4.89</td>\n",
       "      <td>...</td>\n",
       "      <td>0.28</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.94</td>\n",
       "      <td>272</td>\n",
       "      <td>4.40</td>\n",
       "      <td>13.4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>66.5</td>\n",
       "      <td>206.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AFP     AG  Age   ALB  ALP  ALT  AST  BASO#  BASO%   BUN  ...   PCT  \\\n",
       "0   3.58  19.36   47  45.4   56   11   24   0.01   0.30  5.35  ...  0.09   \n",
       "1  34.24  23.98   61  39.9   95    9   13   0.02   0.30  3.21  ...  0.30   \n",
       "2   1.50  18.40   39  45.4   77    9   18   0.03   0.60  3.80  ...  0.13   \n",
       "3   2.75  16.60   45  39.2   26   16   17   0.05   0.74  5.27  ...  0.25   \n",
       "4   2.36  19.97   45  35.0   47   21   27   0.01   0.10  4.89  ...  0.28   \n",
       "\n",
       "    PDW  PHOS  PLT   RBC   RDW  TBIL    TP     UA  TYPE  \n",
       "0  13.4  1.46   74  2.64  13.7   5.5  73.9  396.4     0  \n",
       "1  11.2  1.09  304  4.89  12.7   6.8  72.0  119.2     0  \n",
       "2  15.2  0.97  112  4.62  12.0  14.8  77.9  209.2     0  \n",
       "3  17.4  1.25  339  4.01  14.6  10.9  66.1  215.6     0  \n",
       "4  11.9  0.94  272  4.40  13.4   5.3  66.5  206.0     0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "cancer = pd.read_csv('/Users/sundaramvaibhav/Downloads/SV CODE/Python/DSA/ovariantotal.csv')\n",
    "cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b47ee740-0323-48e0-ad5d-b115b29d4b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349, 50)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f30c6371-9c2e-4cd9-b22e-e9971da38dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating dependent and independent variables - in this case, separating features and labels\n",
    "X = cancer.drop('TYPE', axis = 1)  # axis = 0 means row, axis = 1 means column\n",
    "y = cancer['TYPE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6fc5f9-c75e-4449-aaea-9a8c5569fad7",
   "metadata": {},
   "source": [
    "**fit_transform(X)** <br>\n",
    "\n",
    "**fit(X):** Calculates the minimum and maximum values for each feature (i.e., for each column in X). <br>\n",
    "\n",
    "**transform(X):** Applies the following formula to each value in X: <br>\n",
    "<br>             $X_{\\text{scaled}} = \\frac{x - x_{\\min}}{x_{\\max} - x_{\\min}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d09f2d9e-a557-4632-ac80-1e296437d15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.45578349e-03 4.85071876e-01 4.70588235e-01 ... 8.37988827e-02\n",
      "  7.60667904e-01 5.60447761e-01]\n",
      " [2.78074070e-02 6.55363067e-01 6.76470588e-01 ... 1.20111732e-01\n",
      "  7.25417440e-01 4.32835821e-02]\n",
      " [7.35908185e-04 4.49686694e-01 3.52941176e-01 ... 3.43575419e-01\n",
      "  8.34879406e-01 2.11194030e-01]\n",
      " ...\n",
      " [1.83563615e-03 4.80280133e-01 6.47058824e-01 ... 3.15642458e-01\n",
      "  6.58627087e-01 2.11753731e-01]\n",
      " [1.01704165e-03 7.74788058e-01 2.20588235e-01 ... 2.45810056e-01\n",
      "  7.99628942e-01 3.53917910e-01]\n",
      " [8.26863129e-04 2.50645042e-01 3.52941176e-01 ... 1.62011173e-01\n",
      "  6.62337662e-01 1.65858209e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "print(X_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4a89379-6608-4566-92f9-1d3127a5ef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f291913-40a9-48e5-a216-a3d6a996fbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py311/lib/python3.11/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# number of hidden layers is a hyperparameter, for our model we are choosing 2 hidden layers\\\n",
    "# number of neurins in the hidden layers is also a hyperparameter, we are choosing 32 here\n",
    "# for hidden layer we are choosing ReLU activation function and since this is a binary classification problem, the activation function in the output layer would \n",
    "# be the sigmoid activation function\n",
    "# Dense - every neuron is connected to every other neuron in the next layer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation = 'relu', input_dim = 49))  # first hidden layer\n",
    "model.add(Dense(32, activation = 'relu')) # second hidden layer\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97865798-639c-4315-ae6e-316868b66753",
   "metadata": {},
   "source": [
    "**Given:** <br>\n",
    "\n",
    "Dataset size = 349 samples <br>\n",
    "\n",
    "test_size=0.2 → 20% for testing, so <br>\n",
    "Training set = 80% of 349 = 279 samples (approx.) <br>\n",
    "\n",
    "batch_size = 32 <br>\n",
    "\n",
    "$$\n",
    "\\text{Steps per epoch} = \\left\\lceil \\frac{\\text{Number of training samples}}{\\text{batch size}} \\right\\rceil\n",
    "$$ <br>\n",
    "Here, the steps per epoch are ceil(279/32) = ceilin(8.718) = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e636e07-dfdd-4af2-a2ab-f2f35707c5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5771 - loss: 0.6677  \n",
      "Epoch 2/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6523 - loss: 0.6426\n",
      "Epoch 3/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7240 - loss: 0.6223\n",
      "Epoch 4/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7348 - loss: 0.5958\n",
      "Epoch 5/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7491 - loss: 0.5717\n",
      "Epoch 6/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7563 - loss: 0.5462\n",
      "Epoch 7/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7634 - loss: 0.5225\n",
      "Epoch 8/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7849 - loss: 0.5027\n",
      "Epoch 9/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7957 - loss: 0.4833\n",
      "Epoch 10/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7849 - loss: 0.4705\n",
      "Epoch 11/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7921 - loss: 0.4632\n",
      "Epoch 12/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8065 - loss: 0.4516\n",
      "Epoch 13/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8136 - loss: 0.4394\n",
      "Epoch 14/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8351 - loss: 0.4310\n",
      "Epoch 15/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8280 - loss: 0.4276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x30c97d310>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size = 32, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc4dab6a-b62f-4b31-b053-14d321f7cc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.71212935],\n",
       "       [0.3241959 ],\n",
       "       [0.73526543],\n",
       "       [0.07589307],\n",
       "       [0.89595556],\n",
       "       [0.913263  ],\n",
       "       [0.91836065],\n",
       "       [0.1853667 ],\n",
       "       [0.05707509],\n",
       "       [0.7589335 ],\n",
       "       [0.7627426 ],\n",
       "       [0.21068908],\n",
       "       [0.8901929 ],\n",
       "       [0.3660035 ],\n",
       "       [0.1087938 ],\n",
       "       [0.61308557],\n",
       "       [0.64536583],\n",
       "       [0.8281699 ],\n",
       "       [0.92275786],\n",
       "       [0.40128064],\n",
       "       [0.7224502 ],\n",
       "       [0.7997707 ],\n",
       "       [0.2184442 ],\n",
       "       [0.8681305 ],\n",
       "       [0.05847168],\n",
       "       [0.71207905],\n",
       "       [0.0281382 ],\n",
       "       [0.19439803],\n",
       "       [0.09591747],\n",
       "       [0.7928628 ],\n",
       "       [0.46582735],\n",
       "       [0.4650779 ],\n",
       "       [0.03876346],\n",
       "       [0.23753178],\n",
       "       [0.24673244],\n",
       "       [0.01681486],\n",
       "       [0.50227296],\n",
       "       [0.7273765 ],\n",
       "       [0.1985733 ],\n",
       "       [0.2876878 ],\n",
       "       [0.90933496],\n",
       "       [0.7714142 ],\n",
       "       [0.7440073 ],\n",
       "       [0.8803099 ],\n",
       "       [0.8801978 ],\n",
       "       [0.04768071],\n",
       "       [0.3434141 ],\n",
       "       [0.7774195 ],\n",
       "       [0.05449778],\n",
       "       [0.23791675],\n",
       "       [0.69496554],\n",
       "       [0.7962158 ],\n",
       "       [0.30984092],\n",
       "       [0.37565976],\n",
       "       [0.5390751 ],\n",
       "       [0.77927464],\n",
       "       [0.45242253],\n",
       "       [0.847864  ],\n",
       "       [0.33939445],\n",
       "       [0.7447282 ],\n",
       "       [0.90585446],\n",
       "       [0.39410678],\n",
       "       [0.1908182 ],\n",
       "       [0.89400923],\n",
       "       [0.073841  ],\n",
       "       [0.4731929 ],\n",
       "       [0.25203785],\n",
       "       [0.70596164],\n",
       "       [0.5554633 ],\n",
       "       [0.25715017]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd1650c3-4b47-41e8-a712-db2b779fbc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "y_pred = y_pred.astype(int)\n",
    "import numpy as np\n",
    "np.column_stack((y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6b812a1-039e-4422-8dd9-57e51dea4815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  9]\n",
      " [ 3 26]]\n",
      "0.8285714285714286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.78      0.84        41\n",
      "           1       0.74      0.90      0.81        29\n",
      "\n",
      "    accuracy                           0.83        70\n",
      "   macro avg       0.83      0.84      0.83        70\n",
      "weighted avg       0.84      0.83      0.83        70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now we will check the accuracy\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f879d99-a86e-491b-b10e-58e2f5313f4f",
   "metadata": {},
   "source": [
    "**Confusion Matrix :** <br>\n",
    "$$\n",
    "\\begin{array}{c|cc}\n",
    " & \\text{Actual Positive (1)} & \\text{Actual Negative (0)} \\\\\n",
    "\\hline\n",
    "\\text{Predicted Positive (1)} & TP & FP \\\\\n",
    "\\text{Predicted Negative (0)} & FN & TN \\\\\n",
    "\\end{array}\n",
    "$$ <br>\n",
    "**True Positive (TP):** Model predicted 1 and actual is 1 <br>\n",
    "\n",
    "**False Positive (FP):** Model predicted 1, but actual is 0 (Type I error) <br>\n",
    "\n",
    "**False Negative (FN):** Model predicted 0, but actual is 1 (Type II error) <br>\n",
    "\n",
    "**True Negative (TN):** Model predicted 0 and actual is 0 <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e77cc1b-2de0-4c0e-a3dd-1b4a30286ff3",
   "metadata": {},
   "source": [
    "**Regularization Techniques**\n",
    "\n",
    "1. Dropout\n",
    "2. Early stopping\n",
    "3. L1 and L2 regularization\n",
    "4. Batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36248b0-d7a1-4cd3-96bd-03225387946e",
   "metadata": {},
   "source": [
    "Now we will use different regularization techniques one by one in our model and evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c699f307-a6fe-419b-b9e6-4e8709d623db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py311/lib/python3.11/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5018 - loss: 0.7011  \n",
      "Epoch 2/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5627 - loss: 0.6908\n",
      "Epoch 3/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5627 - loss: 0.6678 \n",
      "Epoch 4/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6022 - loss: 0.6554\n",
      "Epoch 5/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6057 - loss: 0.6478 \n",
      "Epoch 6/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6344 - loss: 0.6343 \n",
      "Epoch 7/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7168 - loss: 0.6124 \n",
      "Epoch 8/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7276 - loss: 0.5955 \n",
      "Epoch 9/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7061 - loss: 0.5909 \n",
      "Epoch 10/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7312 - loss: 0.5846 \n",
      "Epoch 11/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7384 - loss: 0.5661 \n",
      "Epoch 12/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7419 - loss: 0.5598\n",
      "Epoch 13/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7419 - loss: 0.5505 \n",
      "Epoch 14/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7706 - loss: 0.5176\n",
      "Epoch 15/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7742 - loss: 0.5343 \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "[[32  9]\n",
      " [ 4 25]]\n",
      "0.8142857142857143\n"
     ]
    }
   ],
   "source": [
    "# 1. Dropout\n",
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(Dropout(0.2, input_dim=49))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_dim = 49))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train,batch_size=32, epochs=15)\n",
    "\n",
    "# Evaluate performance\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "y_pred = y_pred.astype(int)\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a11c4c9-d120-4bfd-b06a-1f84cfeee02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py311/lib/python3.11/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4798 - loss: 0.7591 - val_accuracy: 0.4286 - val_loss: 0.7453\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4798 - loss: 0.7079 - val_accuracy: 0.4286 - val_loss: 0.6936\n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6233 - loss: 0.6641 - val_accuracy: 0.6607 - val_loss: 0.6695\n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5830 - loss: 0.6721 - val_accuracy: 0.6250 - val_loss: 0.6553\n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6368 - loss: 0.6569 - val_accuracy: 0.6786 - val_loss: 0.6418\n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6054 - loss: 0.6474 - val_accuracy: 0.6607 - val_loss: 0.6317\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6502 - loss: 0.6443 - val_accuracy: 0.7321 - val_loss: 0.6231\n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6502 - loss: 0.6381 - val_accuracy: 0.7500 - val_loss: 0.6120\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6771 - loss: 0.6185 - val_accuracy: 0.7143 - val_loss: 0.5979\n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7444 - loss: 0.5998 - val_accuracy: 0.7321 - val_loss: 0.5874\n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7309 - loss: 0.5834 - val_accuracy: 0.7500 - val_loss: 0.5765\n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7040 - loss: 0.5949 - val_accuracy: 0.7321 - val_loss: 0.5672\n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7444 - loss: 0.5707 - val_accuracy: 0.7321 - val_loss: 0.5546\n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7623 - loss: 0.5438 - val_accuracy: 0.7321 - val_loss: 0.5410\n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7399 - loss: 0.5436 - val_accuracy: 0.7321 - val_loss: 0.5296\n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7220 - loss: 0.5414 - val_accuracy: 0.7679 - val_loss: 0.5238\n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7534 - loss: 0.5304 - val_accuracy: 0.7500 - val_loss: 0.5235\n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7803 - loss: 0.5228 - val_accuracy: 0.7857 - val_loss: 0.5202\n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7713 - loss: 0.4917 - val_accuracy: 0.7679 - val_loss: 0.5058\n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7803 - loss: 0.5001 - val_accuracy: 0.7679 - val_loss: 0.5040\n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7892 - loss: 0.4864 - val_accuracy: 0.7679 - val_loss: 0.4990\n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7578 - loss: 0.5145 - val_accuracy: 0.7679 - val_loss: 0.4918\n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7758 - loss: 0.4685 - val_accuracy: 0.7679 - val_loss: 0.4903\n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7982 - loss: 0.4625 - val_accuracy: 0.7857 - val_loss: 0.4924\n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8206 - loss: 0.4636 - val_accuracy: 0.8036 - val_loss: 0.4883\n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8251 - loss: 0.4583 - val_accuracy: 0.7679 - val_loss: 0.4822\n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8296 - loss: 0.4553 - val_accuracy: 0.8036 - val_loss: 0.4852\n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7848 - loss: 0.4493 - val_accuracy: 0.7857 - val_loss: 0.4870\n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8251 - loss: 0.4493 - val_accuracy: 0.7857 - val_loss: 0.4958\n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8117 - loss: 0.4509 - val_accuracy: 0.7857 - val_loss: 0.4817\n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8206 - loss: 0.4149 - val_accuracy: 0.7857 - val_loss: 0.4768\n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8251 - loss: 0.4215 - val_accuracy: 0.7857 - val_loss: 0.4831\n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8341 - loss: 0.4261 - val_accuracy: 0.7857 - val_loss: 0.4741\n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8161 - loss: 0.4299 - val_accuracy: 0.7857 - val_loss: 0.4737\n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8206 - loss: 0.4256 - val_accuracy: 0.7857 - val_loss: 0.4685\n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8341 - loss: 0.4072 - val_accuracy: 0.7857 - val_loss: 0.4691\n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8161 - loss: 0.3972 - val_accuracy: 0.7857 - val_loss: 0.4686\n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8341 - loss: 0.3871 - val_accuracy: 0.7857 - val_loss: 0.4696\n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8386 - loss: 0.4018 - val_accuracy: 0.7857 - val_loss: 0.4624\n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8117 - loss: 0.4107 - val_accuracy: 0.7857 - val_loss: 0.4599\n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8117 - loss: 0.4320 - val_accuracy: 0.7857 - val_loss: 0.4670\n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8206 - loss: 0.3846 - val_accuracy: 0.8214 - val_loss: 0.4587\n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8296 - loss: 0.4001 - val_accuracy: 0.7679 - val_loss: 0.4703\n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8655 - loss: 0.3585 - val_accuracy: 0.7679 - val_loss: 0.4669\n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8341 - loss: 0.3872 - val_accuracy: 0.8214 - val_loss: 0.4559\n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8475 - loss: 0.3627 - val_accuracy: 0.8036 - val_loss: 0.4578\n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8117 - loss: 0.4030 - val_accuracy: 0.7679 - val_loss: 0.4676\n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8430 - loss: 0.3441 - val_accuracy: 0.7857 - val_loss: 0.4585\n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8430 - loss: 0.3523 - val_accuracy: 0.7857 - val_loss: 0.4497\n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8386 - loss: 0.3544 - val_accuracy: 0.8036 - val_loss: 0.4545\n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8520 - loss: 0.3764 - val_accuracy: 0.8036 - val_loss: 0.4574\n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8475 - loss: 0.3542 - val_accuracy: 0.8036 - val_loss: 0.4533\n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8700 - loss: 0.3479 - val_accuracy: 0.7857 - val_loss: 0.4602\n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8475 - loss: 0.3647 - val_accuracy: 0.8036 - val_loss: 0.4587\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "[[31 10]\n",
      " [ 2 27]]\n",
      "0.8285714285714286\n"
     ]
    }
   ],
   "source": [
    "# 2. Early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=49))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# watches the validation-loss metric during training.\n",
    "\n",
    "# Early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    validation_split=0.2, # 20 % of X_train is set aside internally for validation (so effectively 64 % train + 16 % validation + 20 % test).\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate performance\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "y_pred = y_pred.astype(int)\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "544b461d-eea8-444a-84e4-dd66375c4572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py311/lib/python3.11/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4731 - loss: 1.0661  \n",
      "Epoch 2/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5376 - loss: 1.0311\n",
      "Epoch 3/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5986 - loss: 0.9998\n",
      "Epoch 4/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7061 - loss: 0.9681\n",
      "Epoch 5/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7240 - loss: 0.9377\n",
      "Epoch 6/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7312 - loss: 0.9074 \n",
      "Epoch 7/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7312 - loss: 0.8764\n",
      "Epoch 8/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7814 - loss: 0.8505\n",
      "Epoch 9/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7634 - loss: 0.8207\n",
      "Epoch 10/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7634 - loss: 0.7958\n",
      "Epoch 11/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7670 - loss: 0.7728\n",
      "Epoch 12/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7885 - loss: 0.7507\n",
      "Epoch 13/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7957 - loss: 0.7327\n",
      "Epoch 14/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7957 - loss: 0.7152\n",
      "Epoch 15/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7885 - loss: 0.7014\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "[[33  8]\n",
      " [ 5 24]]\n",
      "0.8142857142857143\n"
     ]
    }
   ],
   "source": [
    "# 3(a.) L1 regularization\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.L1(0.001), input_dim=49))\n",
    "model.add(Dense(32, kernel_regularizer=regularizers.L1(0.001), activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train,batch_size=32, epochs=15)\n",
    "\n",
    "\n",
    "# Evaluate performance\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "y_pred = y_pred.astype(int)\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e0751f56-58e2-432a-a640-85233ae52691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py311/lib/python3.11/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5627 - loss: 0.7518  \n",
      "Epoch 2/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6523 - loss: 0.7263 \n",
      "Epoch 3/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7168 - loss: 0.7061 \n",
      "Epoch 4/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7419 - loss: 0.6869 \n",
      "Epoch 5/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7312 - loss: 0.6624 \n",
      "Epoch 6/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7455 - loss: 0.6404 \n",
      "Epoch 7/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7491 - loss: 0.6172 \n",
      "Epoch 8/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7455 - loss: 0.5962 \n",
      "Epoch 9/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7670 - loss: 0.5764 \n",
      "Epoch 10/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7778 - loss: 0.5622 \n",
      "Epoch 11/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7706 - loss: 0.5472\n",
      "Epoch 12/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7778 - loss: 0.5313 \n",
      "Epoch 13/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7921 - loss: 0.5223\n",
      "Epoch 14/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7885 - loss: 0.5151 \n",
      "Epoch 15/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7957 - loss: 0.5023 \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "[[33  8]\n",
      " [ 3 26]]\n",
      "0.8428571428571429\n"
     ]
    }
   ],
   "source": [
    "# 3(b.) L2 regularization\n",
    "\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.L2(0.001), input_dim=49))\n",
    "model.add(Dense(32, kernel_regularizer=regularizers.L2(0.001), activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train,batch_size=32, epochs=15)\n",
    "\n",
    "# Evaluate performance\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "y_pred = y_pred.astype(int)\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b884427a-4710-44cf-aee4-f0e35bf06dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py311/lib/python3.11/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5341 - loss: 0.9395  \n",
      "Epoch 2/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5842 - loss: 0.8425\n",
      "Epoch 3/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6595 - loss: 0.7191\n",
      "Epoch 4/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6989 - loss: 0.6722 \n",
      "Epoch 5/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6774 - loss: 0.6503 \n",
      "Epoch 6/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7419 - loss: 0.5851 \n",
      "Epoch 7/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6703 - loss: 0.6351 \n",
      "Epoch 8/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7276 - loss: 0.5806 \n",
      "Epoch 9/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6882 - loss: 0.6359 \n",
      "Epoch 10/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7348 - loss: 0.6166\n",
      "Epoch 11/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7563 - loss: 0.5342 \n",
      "Epoch 12/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7742 - loss: 0.5309\n",
      "Epoch 13/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7455 - loss: 0.5500 \n",
      "Epoch 14/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7563 - loss: 0.5450 \n",
      "Epoch 15/15\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7384 - loss: 0.5604 \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "[[25 16]\n",
      " [ 1 28]]\n",
      "0.7571428571428571\n"
     ]
    }
   ],
   "source": [
    "# 4. Batch normalization\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "\n",
    "# Define the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer + 1st hidden layer\n",
    "model.add(Dense(32, activation='relu', input_dim=49))\n",
    "model.add(BatchNormalization())          # Normalize activations to stabilize learning\n",
    "model.add(Dropout(0.3))                  # Optional: Dropout for regularization\n",
    "\n",
    "# 2nd hidden layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())          # Normalize the second layer's activations\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # Binary classification output\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train,batch_size=32, epochs=15)\n",
    "\n",
    "\n",
    "# Evaluate performance\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "y_pred = y_pred.astype(int)\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
